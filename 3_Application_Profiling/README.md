# 3. Application Profiling

## 3.1. Profile
许多代码用相对少量的代码完成了大量工作。开发人员可以使用分析器识别这些热点，并开始编制并行化候选项的列表。

### 3.1.1. Creating the Profile
有许多种可能的方法来分析代码，但目标都是相同的：确定应用程序在执行过程中花费最多时间的函数或功能。
```
高优先级：为了最大化开发人员的生产力，分析应用程序以确定热点和瓶颈。
```

最重要的考虑是确保工作负载是现实的，即从测试中获得的信息和基于这些信息做出的决策与实际数据相关。使用不现实的工作负载可能会导致次优结果和浪费精力，因为这会导致开发人员为不现实的问题规模进行优化，并使开发人员集中在错误的功能上。

有许多工具可以用于生成性能剖析。以下示例基于 gprof，这是 GNU Binutils 集合中的一个用于 Linux 平台的开源性能分析器。
```
$ gcc -O2 -g -pg myprog.c
$ gprof ./a.out > profile.txt
Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 33.34      0.02     0.02     7208     0.00     0.00  genTimeStep
 16.67      0.03     0.01      240     0.04     0.12  calcStats
 16.67      0.04     0.01        8     1.25     1.25  calcSummaryData
 16.67      0.05     0.01        7     1.43     1.43  write
 16.67      0.06     0.01                             mcount
  0.00      0.06     0.00      236     0.00     0.00  tzset
  0.00      0.06     0.00      192     0.00     0.00  tolower
  0.00      0.06     0.00       47     0.00     0.00  strlen
  0.00      0.06     0.00       45     0.00     0.00  strchr
  0.00      0.06     0.00        1     0.00    50.00  main
  0.00      0.06     0.00        1     0.00     0.00  memcpy
  0.00      0.06     0.00        1     0.00    10.11  print
  0.00      0.06     0.00        1     0.00     0.00  profil
  0.00      0.06     0.00        1     0.00    50.00  report
```

### 3.1.2. Identifying Hotspots
在上述例子中，我们可以清楚地看到函数 genTimeStep() 占据了应用程序总运行时间的三分之一。这应该是我们并行化的首选候选函数。《Understanding Scaling》讨论了我们可以从这种并行化中预期的潜在收益。

值得注意的是，在上述例子中，其他几个函数也占据了整体运行时间的很大一部分，例如 calcStats() 和 calcSummaryData()。同样地，并行化这些函数也应该增加我们的加速潜力。然而，由于 APOD 是一个循环过程，我们可以选择在后续的 APOD 过程中并行化这些函数，从而将任何一次工作范围限制在一小部分增量更改。

### 3.1.3. Understanding Scaling
应用程序通过在 CUDA 上运行所获得的性能收益完全取决于它的并行化程度。不能充分并行化的代码应在主机上运行，除非这样做会导致在主机和 device 之间进行大量数据传输。
```
高优先级：为了最大限度地利用 CUDA 的优势，首先应关注找到方法将顺序代码并行化。
```

通过了解应用程序如何扩展，可以设定预期并规划逐步并行化的策略。《Strong Scaling and Amdahl’s Law》描述了强扩展，它允许我们为固定问题规模设定加速的上限。《Weak Scaling and Gustafson’s Law》描述了弱扩展，其中通过增加问题规模来实现加速。在许多应用程序中，强扩展和弱扩展的结合是理想的。

#### 3.1.3.1. Strong Scaling and Amdahl’s Law
强扩展是衡量在固定整体问题规模的情况下，随着系统中添加更多处理器，解决问题所需时间减少的程度。展示线性强扩展的应用程序的加速比等于使用的处理器数量。

强扩展通常与阿姆达尔法则联系在一起，该法则规定了通过并行化串行程序的部分代码所能获得的最大加速比。基本上，它指出程序的最大加速比 S 是：

$$ S = \frac{1}{(1 - P) + \frac{P}{N}} $$

其中，P 是可以并行化的代码部分在总串行执行时间中所占的比例，N 是并行部分代码运行的处理器数量。

N 越大（即处理器数量越多），P/N 比例越小。可以更简单地将 N 视为一个非常大的数，这实际上将方程式转换为：

$$ S ≈ \frac{1}{(1 - P)} $$

现在，如果将顺序程序运行时间的 3/4 并行化，那么串行代码的最大加速比为 1 / (1 - 3/4) = 4。

实际上，即使大多数应用程序展示出某种程度的强扩展，它们也不一定完全呈现出线性强扩展。对于大多数情况来说，关键点是并行化部分 P 越大，潜在加速比越大。反之，如果 P 是一个小数（意味着应用程序不太能并行化），增加处理器数量 N 对性能的提升作用不大。因此，为了在固定问题规模下获得最大加速比，值得努力增加 P，即最大化可并行化的代码量。

#### Weak Scaling and Gustafson’s Law

弱扩展是衡量在每个处理器的固定问题规模下，随着系统中添加更多处理器，解决问题所需时间的变化程度；即随着处理器数量的增加，总问题规模也增加。

弱扩展通常与古斯塔夫森法则联系在一起，该法则指出，在实际中，问题规模随处理器数量扩展。因此，程序的最大加速比 S 是：

$$ S = N - (N - 1) \cdot P $$

其中，P 是可以并行化的代码部分在总串行执行时间中所占的比例，N 是并行部分代码运行的处理器数量。

另一种理解古斯塔夫森法则的方法是，在扩展系统时，不是问题规模保持不变，而是执行时间保持不变。需要注意的是，古斯塔夫森法则假设串行与并行执行的比例保持不变，这反映了设置和处理更大问题所需的额外成本。

#### 3.1.3.3. Applying Strong and Weak Scaling

了解哪种类型的扩展最适用于应用程序是估算加速比的重要部分。对于某些应用程序，问题规模将保持不变，因此只适用强扩展。一个例子是模拟两个分子相互作用，其中分子大小是固定的。

对于其他应用程序，问题规模会随着可用处理器的增加而增长。例子包括将流体或结构建模为网格或格子，以及某些蒙特卡罗模拟，其中增加问题规模可以提高准确性。

在了解应用程序特征后，开发人员应了解如果计算性能发生变化，问题规模将如何变化，然后应用Amdahl’s or Gustafson’s 法则来确定加速比的上限。

